/*
 * Omni Realtime ViewModel
 * Manages real-time multimodal conversation with AI
 */

import Foundation
import SwiftUI
import AVFoundation
import UIKit

@MainActor
class OmniRealtimeViewModel: ObservableObject {

    // Published state
    @Published var isConnected = false
    @Published var isRecording = false
    @Published var isSpeaking = false
    @Published var currentTranscript = ""
    @Published var conversationHistory: [ConversationMessage] = []
    @Published var errorMessage: String?
    @Published var showError = false

    // Service
    private var omniService: OmniRealtimeService
    private let apiKey: String
    private let enableImageInput: Bool
    private let qualitySettings: AIQualitySettings
    private let recordCategory: ConversationCategory
    private var recordLanguage: String
    private var isSessionActive = false
    private var shouldReconnectOnForeground = false
    private var shouldRestartRecording = false
    private var isConnecting = false
    private var isAttemptingReconnect = false
    private var notificationTokens: [NSObjectProtocol] = []
    private var shouldIgnoreErrors = false
    private var hasSavedConversation = false

    // Video frame
    private var currentVideoFrame: UIImage?
    private var isImageSendingEnabled = false // æ˜¯å¦å·²å¯ç”¨å›¾ç‰‡å‘é€ï¼ˆç¬¬ä¸€æ¬¡éŸ³é¢‘åï¼‰
    private var pendingImageAttachments: [ConversationImageAttachment] = []
    private var pendingUserMessageID: UUID?

    init(
        apiKey: String,
        enableImageInput: Bool = true,
        qualitySettings: AIQualitySettings = .shared,
        sessionInstructions: String = OmniRealtimeService.defaultInstructions,
        recordCategory: ConversationCategory = .liveAI,
        recordLanguage: String = "zh-CN"
    ) {
        self.apiKey = apiKey
        self.enableImageInput = enableImageInput
        self.qualitySettings = qualitySettings
        self.recordCategory = recordCategory
        self.recordLanguage = recordLanguage
        self.omniService = OmniRealtimeService(apiKey: apiKey, sessionInstructions: sessionInstructions)
        setupCallbacks()
        registerAppLifecycleObservers()
    }

    // MARK: - Setup

    private func setupCallbacks() {
        omniService.onConnected = { [weak self] in
            Task { @MainActor in
                guard let self else { return }
                self.isConnected = true
                self.isConnecting = false
                self.shouldReconnectOnForeground = false

                if self.shouldRestartRecording {
                    self.shouldRestartRecording = false
                    self.startRecording()
                }
            }
        }

        omniService.onFirstAudioSent = { [weak self] in
            Task { @MainActor in
                guard let self, self.enableImageInput else { return }
                print("âœ… [OmniVM] æ”¶åˆ°ç¬¬ä¸€æ¬¡éŸ³é¢‘å‘é€å›è°ƒï¼Œå¯ç”¨å›¾ç‰‡å‘é€")
                // å»¶è¿Ÿ1ç§’åå¯ç”¨å›¾ç‰‡å‘é€èƒ½åŠ›ï¼ˆç¡®ä¿éŸ³é¢‘å·²åˆ°è¾¾ï¼‰
                DispatchQueue.main.asyncAfter(deadline: .now() + 1.0) {
                    self.isImageSendingEnabled = true
                    print("ğŸ“¸ [OmniVM] å›¾ç‰‡å‘é€å·²å¯ç”¨ï¼Œç­‰å¾…ç”¨æˆ·è¯­éŸ³è§¦å‘")
                }
            }
        }

        omniService.onSpeechStarted = { [weak self] in
            Task { @MainActor in
                self?.isSpeaking = true

                // ç”¨æˆ·è¯­éŸ³è§¦å‘æ¨¡å¼ï¼šæ£€æµ‹åˆ°ç”¨æˆ·å¼€å§‹è¯´è¯æ—¶ï¼Œå‘é€ä¸€å¸§å›¾ç‰‡
                if let strongSelf = self,
                   strongSelf.enableImageInput,
                   strongSelf.isImageSendingEnabled,
                   let frame = strongSelf.currentVideoFrame {
                    if !strongSelf.pendingImageAttachments.isEmpty {
                        ConversationImageStorage.shared.deleteImages(strongSelf.pendingImageAttachments)
                    }
                    strongSelf.pendingImageAttachments = []
                    strongSelf.pendingUserMessageID = UUID()
                    strongSelf.sendKeyFrames(from: frame)
                }
            }
        }

        omniService.onSpeechStopped = { [weak self] in
            Task { @MainActor in
                self?.isSpeaking = false
            }
        }

        omniService.onTranscriptDelta = { [weak self] delta in
            Task { @MainActor in
//                print("ğŸ“ [OmniVM] AIå›å¤ç‰‡æ®µ: \(delta)")
                self?.currentTranscript += delta
            }
        }

        omniService.onUserTranscript = { [weak self] userText in
            Task { @MainActor in
                guard let self = self else { return }
                print("ğŸ’¬ [OmniVM] ä¿å­˜ç”¨æˆ·è¯­éŸ³: \(userText)")
                let messageID = self.pendingUserMessageID ?? UUID()
                let attachments = self.pendingImageAttachments
                self.pendingImageAttachments = []
                self.pendingUserMessageID = messageID
                self.conversationHistory.append(
                    ConversationMessage(
                        id: messageID,
                        role: .user,
                        content: userText,
                        imageAttachments: attachments
                    )
                )
                self.scheduleAttachmentFinalization(for: messageID)
            }
        }

        omniService.onTranscriptDone = { [weak self] fullText in
            Task { @MainActor in
                guard let self = self else { return }
                // ä½¿ç”¨ç´¯ç§¯çš„currentTranscriptï¼Œå› ä¸ºdoneäº‹ä»¶å¯èƒ½ä¸åŒ…å«textå­—æ®µ
                let textToSave = fullText.isEmpty ? self.currentTranscript : fullText
                guard !textToSave.isEmpty else {
                    print("âš ï¸ [OmniVM] AIå›å¤ä¸ºç©ºï¼Œè·³è¿‡ä¿å­˜")
                    return
                }
                print("ğŸ’¬ [OmniVM] ä¿å­˜AIå›å¤: \(textToSave)")
                self.conversationHistory.append(
                    ConversationMessage(role: .assistant, content: textToSave)
                )
                self.currentTranscript = ""
            }
        }

        omniService.onAudioDone = { [weak self] in
            Task { @MainActor in
                // Audio playback complete
            }
        }

        omniService.onError = { [weak self] error in
            Task { @MainActor in
                guard let self else { return }
                self.isConnecting = false

                guard self.isSessionActive else {
                    return
                }

                let isForeground = UIApplication.shared.applicationState == .active
                if !isForeground {
                    self.shouldReconnectOnForeground = true
                    self.shouldRestartRecording = self.isRecording || self.shouldRestartRecording
                    return
                }

                if self.shouldAttemptReconnect(for: error) {
                    self.shouldReconnectOnForeground = false
                    self.shouldRestartRecording = self.isRecording || self.shouldRestartRecording
                    self.reconnect()
                    return
                }

                if self.shouldIgnoreErrors {
                    return
                }

                self.errorMessage = error
                self.showError = true
            }
        }
    }

    // MARK: - Connection

    func connect() {
        guard !isConnecting else { return }
        guard UIApplication.shared.applicationState == .active else {
            shouldReconnectOnForeground = true
            return
        }
        if !isSessionActive {
            hasSavedConversation = false
            resetConversationState()
        }
        isSessionActive = true
        shouldIgnoreErrors = UIApplication.shared.applicationState != .active
        isConnecting = true
        omniService.connect()
    }

    func disconnect() {
        // Save conversation before disconnecting
        saveConversationIfNeeded()

        shouldIgnoreErrors = true
        shouldRestartRecording = isRecording
        stopRecording()
        omniService.disconnect()
        isConnected = false
        isImageSendingEnabled = false
        isConnecting = false
        isSessionActive = false
        isAttemptingReconnect = false
        if !pendingImageAttachments.isEmpty {
            ConversationImageStorage.shared.deleteImages(pendingImageAttachments)
        }
        pendingImageAttachments = []
        pendingUserMessageID = nil
        shouldReconnectOnForeground = false
        shouldRestartRecording = false
        unregisterAppLifecycleObservers()
    }

    private func saveConversation() {
        // Only save if there's meaningful conversation
        guard !conversationHistory.isEmpty else {
            print("ğŸ’¬ [OmniVM] æ— å¯¹è¯å†…å®¹ï¼Œè·³è¿‡ä¿å­˜")
            return
        }

        let record = ConversationRecord(
            messages: conversationHistory,
            aiModel: "qwen3-omni-flash-realtime",
            language: recordLanguage,
            category: recordCategory
        )

        ConversationStorage.shared.saveConversation(record)
        print("ğŸ’¾ [OmniVM] å¯¹è¯å·²ä¿å­˜: \(conversationHistory.count) æ¡æ¶ˆæ¯")
    }

    private func saveConversationIfNeeded() {
        guard !hasSavedConversation else { return }
        hasSavedConversation = true
        saveConversation()
    }

    private func resetConversationState() {
        if !pendingImageAttachments.isEmpty {
            ConversationImageStorage.shared.deleteImages(pendingImageAttachments)
        }
        pendingImageAttachments = []
        pendingUserMessageID = nil
        currentTranscript = ""
        conversationHistory = []
        errorMessage = nil
        showError = false
        isSpeaking = false
    }

    // MARK: - Recording

    func startRecording() {
        guard !isRecording else { return }
        guard isConnected else {
            print("âš ï¸ [OmniVM] æœªè¿æ¥ï¼Œæ— æ³•å¼€å§‹å½•éŸ³")
            errorMessage = "è¯·å…ˆè¿æ¥æœåŠ¡å™¨"
            showError = true
            return
        }

        print("ğŸ¤ [OmniVM] å¼€å§‹å½•éŸ³ï¼ˆè¯­éŸ³è§¦å‘æ¨¡å¼ï¼‰")
        omniService.startRecording()
        isRecording = true
    }

    func stopRecording() {
        guard isRecording else { return }
        print("ğŸ›‘ [OmniVM] åœæ­¢å½•éŸ³")
        omniService.stopRecording()
        isRecording = false
    }

    // MARK: - Video Frames

    func updateVideoFrame(_ frame: UIImage) {
        guard enableImageInput else { return }
        currentVideoFrame = frame
    }

    private func sendKeyFrames(from frame: UIImage) {
        let count = max(1, min(qualitySettings.keyFrameCount, 3))
        let maxDimension = qualitySettings.aiImageMaxDimension.rawValue
        let quality = qualitySettings.aiImageQuality

        for index in 0..<count {
            let delay = Double(index) * 0.15
            DispatchQueue.main.asyncAfter(deadline: .now() + delay) { [weak self] in
                guard let self else { return }
                let latestFrame = self.currentVideoFrame ?? frame
                if let attachment = ConversationImageStorage.shared.saveAttachment(
                    latestFrame,
                    aiMaxDimension: maxDimension,
                    aiQuality: quality
                ) {
                    self.appendImageAttachment(attachment)
                }
                self.omniService.sendImageAppend(
                    latestFrame,
                    maxDimension: maxDimension,
                    quality: quality
                )
            }
        }
    }

    private func appendImageAttachment(_ attachment: ConversationImageAttachment) {
        if let messageID = pendingUserMessageID,
           let index = conversationHistory.firstIndex(where: { $0.id == messageID }) {
            var message = conversationHistory[index]
            message.imageAttachments.append(attachment)
            conversationHistory[index] = message
        } else {
            pendingImageAttachments.append(attachment)
        }
    }

    private func scheduleAttachmentFinalization(for messageID: UUID) {
        let count = max(1, min(qualitySettings.keyFrameCount, 3))
        let attachmentDelay = Double(count - 1) * 0.15 + 0.5

        DispatchQueue.main.asyncAfter(deadline: .now() + attachmentDelay) { [weak self] in
            guard let self else { return }
            if self.pendingUserMessageID == messageID {
                self.pendingUserMessageID = nil
                self.pendingImageAttachments.removeAll()
            }
        }
    }

    // MARK: - Manual Mode (if needed)

    func sendMessage() {
        omniService.commitAudioBuffer()
    }

    // MARK: - Cleanup

    func dismissError() {
        showError = false
    }

    func updateSessionInstructions(_ instructions: String) {
        omniService.updateSessionInstructions(instructions)
    }

    func updateRecordLanguage(_ language: String) {
        recordLanguage = language
    }

    private func registerAppLifecycleObservers() {
        guard notificationTokens.isEmpty else { return }
        let center = NotificationCenter.default
        let backgroundToken = center.addObserver(
            forName: UIApplication.didEnterBackgroundNotification,
            object: nil,
            queue: .main
        ) { [weak self] _ in
            self?.handleDidEnterBackground()
        }
        let foregroundToken = center.addObserver(
            forName: UIApplication.willEnterForegroundNotification,
            object: nil,
            queue: .main
        ) { [weak self] _ in
            self?.handleWillEnterForeground()
        }
        notificationTokens = [backgroundToken, foregroundToken]
    }

    private func unregisterAppLifecycleObservers() {
        notificationTokens.forEach { NotificationCenter.default.removeObserver($0) }
        notificationTokens.removeAll()
    }

    private func handleDidEnterBackground() {
        shouldIgnoreErrors = true
        if isConnected || isRecording {
            shouldReconnectOnForeground = true
            shouldRestartRecording = isRecording || shouldRestartRecording
        }
    }

    private func handleWillEnterForeground() {
        shouldIgnoreErrors = false
        guard shouldReconnectOnForeground else { return }
        reconnect()
    }

    private func reconnect() {
        guard !isAttemptingReconnect else { return }
        isAttemptingReconnect = true

        shouldIgnoreErrors = true
        stopRecording()
        omniService.disconnect()
        isConnected = false
        isConnecting = false

        let isForeground = UIApplication.shared.applicationState == .active
        shouldReconnectOnForeground = !isForeground

        guard isForeground else {
            isAttemptingReconnect = false
            return
        }

        Task { @MainActor in
            try? await Task.sleep(nanoseconds: 400_000_000)
            self.shouldIgnoreErrors = false
            self.connect()
            self.isAttemptingReconnect = false
        }
    }

    private func shouldAttemptReconnect(for error: String) -> Bool {
        let lowercased = error.lowercased()
        if lowercased.contains("software caused connection abort")
            || lowercased.contains("connection aborted")
            || lowercased.contains("connection was lost")
            || lowercased.contains("network connection was lost")
            || lowercased.contains("broken pipe") {
            return true
        }

        if error.contains("è¿æ¥ç»ˆæ­¢")
            || error.contains("è¿æ¥å·²ç»ˆæ­¢")
            || error.contains("è½¯ä»¶å¯¼è‡´è¿æ¥ç»ˆæ­¢")
            || error.contains("ç½‘ç»œè¿æ¥å·²æ–­å¼€") {
            return true
        }

        return false
    }

    deinit {
        notificationTokens.forEach { NotificationCenter.default.removeObserver($0) }
        Task { @MainActor [weak omniService] in
            omniService?.disconnect()
        }
    }
}

// MARK: - Conversation Message

struct ConversationMessage: Identifiable {
    let id: UUID
    let role: MessageRole
    let content: String
    let timestamp: Date
    var imageAttachments: [ConversationImageAttachment]

    enum MessageRole {
        case user
        case assistant
    }

    init(
        id: UUID = UUID(),
        role: MessageRole,
        content: String,
        timestamp: Date = Date(),
        imageAttachments: [ConversationImageAttachment] = []
    ) {
        self.id = id
        self.role = role
        self.content = content
        self.timestamp = timestamp
        self.imageAttachments = imageAttachments
    }
}
